{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f66204",
   "metadata": {},
   "source": [
    "### 데이터 직렬화: 텐서를 파일로 보관했다가 나중에 다시 읽기 위해 필요\n",
    "- 파이토치에서는 내부적으로 pickle을 사용\n",
    "- 저장 공간을 위한 전용 직렬화 코드를 가지고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b2371",
   "metadata": {},
   "source": [
    "### PyTorch로만 데이터를 저장하고 로드하는 경우\n",
    "- torch.save()와 torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbae20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "points = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc4fa8",
   "metadata": {},
   "source": [
    "points 텐서를 ourpoints.t 파일에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69dbc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, '../data/p1ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b67eb",
   "metadata": {},
   "source": [
    "혹은 파일 이름 대신 파일 descriptor를 넣어도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095280d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/p1ch3/ourpoints.t', 'wb') as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a4f13",
   "metadata": {},
   "source": [
    "텐서로 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308777c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load('../data/p1ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb4f8a",
   "metadata": {},
   "source": [
    "혹은 (이렇게 사용할리는 없겠지만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e210f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/p1ch3/ourpoints.t', 'rb') as f:\n",
    "    points = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bdc93",
   "metadata": {},
   "source": [
    "하지만, PyTorch를 사용해야하기 때문에 다른 딥러닝 프레임워크를 사용하고 있는 시스템이 있는 상태에서 호환성 문제가 발생할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29029d",
   "metadata": {},
   "source": [
    "### HDF5 : 호환성이 중요할 경우 사용\n",
    "- 이식성이 높고 광범위하게 지원됨\n",
    "- 중첩된 키-값 딕셔너리에서 직렬화된 정형 다차원 배열을 표현하는 포맷\n",
    "- 파이썬에서는 h5py 라이브러리를 통해 HDF5 포맷을 지원\n",
    "- Numpy 배열 형태로 전달하거나 반환 받을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40674a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install h5py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1f9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38d6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'w')\n",
    "dset = f.create_dataset('coord', data=points.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ecc9c",
   "metadata": {},
   "source": [
    "'coord' : HDF5 파일의 키에 해당하는데 키와 키를 중첩(nested) 시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c718809",
   "metadata": {},
   "source": [
    "데이터셋의 가장 뒤 포인트 2개만 읽고 싶다면 numpy에서와 유사하게 데이터셋을 slicing해 가져올 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120fe8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'r')\n",
    "dset = f['coord']\n",
    "last_points = dset[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046db256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2544861 , -0.9302548 ,  2.099093  ],\n",
       "       [-0.5908261 ,  1.2951008 , -0.48101923]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a00f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_points_t = torch.from_numpy(dset[-2:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9358b853",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dset_id is not a dataset id (dset_id is not a dataset ID)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/py38/lib/python3.8/site-packages/h5py/_hl/dataset.py:741\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_selector.pyx:370\u001b[0m, in \u001b[0;36mh5py._selector.Reader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dset_id is not a dataset id (dset_id is not a dataset ID)"
     ]
    }
   ],
   "source": [
    "dset[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63759c",
   "metadata": {},
   "source": [
    "파일이 닫히고 나서는 데이터셋에 접근할 수 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ec352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
